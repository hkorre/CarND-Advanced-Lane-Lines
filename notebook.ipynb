{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Advanced Lane Finding** \n",
    "\n",
    "---\n",
    "By Hasan Korre\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply the distortion correction to the raw image.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find lane boundary.\n",
    "* Determine curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing Frames from Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.editor import VideoFileClip\n",
    "%matplotlib inline\n",
    "\n",
    "def grab_video_frame(filepath_, frame_):\n",
    "    clip = VideoFileClip(filepath_)\n",
    "    return clip.get_frame(frame_)\n",
    "\n",
    "# image should be RGB\n",
    "def save_image(img_, filepath_):\n",
    "    mpimg.imsave(filepath_, img_)\n",
    "\n",
    "\n",
    "## try it ######\n",
    "frame_num = 10\n",
    "test_frame = grab_video_frame('challenge_video.mp4', frame_num)\n",
    "plt.imshow(test_frame)\n",
    "\n",
    "'''\n",
    "SAVE_FOLDER = 'challenge_frames/'\n",
    "save_name = SAVE_FOLDER + 'challenge_{}.jpg'.format(frame_num)\n",
    "save_image(test_frame, save_name)\n",
    "'''\n",
    "\n",
    "print('Success: Defined functions to grab video frames.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration (Distortion Correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "# Read in a calibration image\n",
    "img = mpimg.imread('camera_cal/calibration2.jpg')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corner Detection for 1 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Arrays to store object points and image points from all the images\n",
    "obj_points = []  #3D points in real world space\n",
    "img_points = []  #2D point in image plane\n",
    "\n",
    "# Prepare object points, like (0,0,0), (1,0,0), (2,0,0), (8,5,0)\n",
    "nx = 9  #num of inside corners in x\n",
    "ny = 6  #num of inside corners in y\n",
    "objp = np.zeros((ny*nx,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Convert image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Find the chessboard corners\n",
    "ret, corners = cv2.findChessboardCorners(gray,(nx, ny), None)\n",
    "\n",
    "# If corners are found, add object points and image points\n",
    "if ret == True:\n",
    "    img_points.append(corners)\n",
    "    obj_points.append(objp)\n",
    "    \n",
    "    # Draw and display the corners\n",
    "    cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "    plt.imshow(img)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrate the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Read in and make a list of calibration image\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Arrays to store object points and image points from all the images\n",
    "obj_points = []  #3D points in real world space\n",
    "img_points = []  #2D point in image plane\n",
    "\n",
    "# Prepare object points, like (0,0,0), (1,0,0), (2,0,0), (8,5,0)\n",
    "nx = 9  #num of inside corners in x\n",
    "ny = 6  #num of inside corners in y\n",
    "objp = np.zeros((ny*nx,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "for filename in images:\n",
    "    # read in each image\n",
    "    img = mpimg.imread(filename)\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray,(nx, ny), None)\n",
    "\n",
    "    # If corners are found, add object points and image points\n",
    "    if ret == True:\n",
    "        img_points.append(corners)\n",
    "        obj_points.append(objp)\n",
    "\n",
    "# Calibrate the camera\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(obj_points, img_points, img_size, None, None)\n",
    "\n",
    "print('Success: Calibrated camera.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undistort an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Undistortion function\n",
    "#   mtx_  = camera matrix\n",
    "#   dist_ = distortion coefficients\n",
    "def cal_undistort(img_, mtx_, dist_):\n",
    "    return cv2.undistort(img_, mtx_, dist_, None, mtx_)\n",
    "\n",
    "# Test\n",
    "img_original = mpimg.imread('camera_cal/calibration5.jpg')\n",
    "img_undistort = cal_undistort(img_original, mtx, dist)\n",
    "\n",
    "# Display\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img_original)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(img_undistort)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a thresholded binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "print('Success: Imports done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_img = mpimg.imread('test_images/test3.jpg')\n",
    "#test_img = mpimg.imread('challenge_frames/challenge_10.jpg')\n",
    "#test_img = mpimg.imread('test_images/solidWhiteRight.jpg')\n",
    "\n",
    "# Display the image                 \n",
    "plt.imshow(test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Color Selection:\n",
    "Goal: Keep only yellow and white in the image (lane colors)\n",
    "\"\"\"\n",
    "def color_select(img_):\n",
    "    # Grab the x and y size and make a copy of the image\n",
    "    ysize = img_.shape[0]\n",
    "    xsize = img_.shape[1]\n",
    "    color_select = np.copy(img_)\n",
    "    \n",
    "    # Define our color selection criteria\n",
    "    red_threshold = 160 #180\n",
    "    green_threshold = 150\n",
    "    blue_threshold = 0\n",
    "    # max values of rgb allowed\n",
    "    rgb_threshold = [red_threshold, green_threshold, blue_threshold]\n",
    "    \n",
    "    # Use a \"bitwise OR\" to identify pixels below the threshold\n",
    "    thresholds = (img_[:,:,0] < rgb_threshold[0]) \\\n",
    "                  | (img_[:,:,1] < rgb_threshold[1]) \\\n",
    "                  | (img_[:,:,2] < rgb_threshold[2])\n",
    "    color_select[thresholds] = [0,0,0]    \n",
    "    return color_select\n",
    "\n",
    "\n",
    "'''\n",
    "run it...\n",
    "'''\n",
    "test_colorSelect = color_select(test_img)\n",
    "\n",
    "# Display\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(test_img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(test_colorSelect)\n",
    "ax2.set_title('Color Selected Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Transform and Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert to HLS color space and separate the S channel\n",
    "def rgb_to_s(img_):   \n",
    "    hls = cv2.cvtColor(img_, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    return s_channel\n",
    "\n",
    "# Threshold color channel\n",
    "def threshold_color(img_channel_, s_thresh_min_, s_thresh_max_):\n",
    "    s_binary = np.zeros_like(img_channel_)\n",
    "    s_binary[(img_channel_ >= s_thresh_min_) & (img_channel_ <= s_thresh_max_)] = 1\n",
    "    return s_binary\n",
    "\n",
    "'''\n",
    "run it...\n",
    "'''\n",
    "test_sChannel = rgb_to_s(test_colorSelect)\n",
    "\n",
    "MIN_COLOR_THRESHOLD = 100\n",
    "MAX_COLOR_THRESHOLD = 255\n",
    "test_color_thresh = threshold_color(test_sChannel, \n",
    "                                    MIN_COLOR_THRESHOLD, \n",
    "                                    MAX_COLOR_THRESHOLD)\n",
    "\n",
    "# Display\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(test_sChannel, cmap='gray')\n",
    "ax1.set_title('S-Channel', fontsize=50)\n",
    "ax2.imshow(test_color_thresh, cmap='gray')\n",
    "ax2.set_title('Thresholded S-Channel', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Sobel Transform and Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RBG to Grayscale\n",
    "def rbg_to_gray(img_):\n",
    "    return cv2.cvtColor(img_, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Define a function that takes an image, gradient orientation,\n",
    "# and threshold min / max values.\n",
    "def abs_sobel_thresh(img_, orient_='x', thresh_min_=0, thresh_max_=255):\n",
    "    gray = rbg_to_gray(img_)\n",
    "    if orient_ == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "    if orient_ == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n",
    "    # Rescale back to 8-bit\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh_min_) & (scaled_sobel <= thresh_max_)] = 1\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "# Define a function to return the magnitude of the gradient\n",
    "# for a given sobel kernel size and threshold values\n",
    "def mag_thresh(img_, sobel_kernel_=3, mag_thresh_=(0, 255)):\n",
    "    gray = rbg_to_gray(img_)\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel_)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel_)\n",
    "    # Calculate the gradient magnitude\n",
    "    grad_mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit \n",
    "    grad_mag = np.uint8(255*grad_mag/np.max(grad_mag))\n",
    "    # Create binary image\n",
    "    binary_output = np.zeros_like(grad_mag)\n",
    "    binary_output[(grad_mag >= mag_thresh_[0]) & (grad_mag <= mag_thresh_[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "# Define a function to threshold an image for a given range and Sobel kernel\n",
    "def dir_threshold(img_, sobel_kernel_=3, thresh_=(0, np.pi/2)):\n",
    "    gray = rbg_to_gray(img_)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel_)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel_)\n",
    "    abs_gradDir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    # Create binary image\n",
    "    binary_output =  np.zeros_like(abs_gradDir)\n",
    "    binary_output[(abs_gradDir >= thresh_[0]) & (abs_gradDir <= thresh_[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "def sobel_complex_combine(image_):\n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(image_, orient_='x', thresh_min_=20, thresh_max_=100)\n",
    "    grady = abs_sobel_thresh(image_, orient_='y', thresh_min_=20, thresh_max_=100)\n",
    "    mag_binary = mag_thresh(image_, sobel_kernel_=3, mag_thresh_=(30, 100))\n",
    "    dir_binary = dir_threshold(image_, sobel_kernel_=15, thresh_=(0.7, 1.3))\n",
    "    \n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    return combined.astype(np.uint8)\n",
    "\n",
    "\n",
    "'''\n",
    "run it...\n",
    "'''\n",
    "test_abs_sobelx = abs_sobel_thresh(test_colorSelect, orient_='x', thresh_min_=20, thresh_max_=100)\n",
    "test_abs_sobely = abs_sobel_thresh(test_colorSelect, orient_='y', thresh_min_=20, thresh_max_=100)\n",
    "test_mag_sobel = mag_thresh(test_colorSelect, sobel_kernel_=3, mag_thresh_=(30, 100))\n",
    "test_dir_sobel = dir_threshold(test_colorSelect, sobel_kernel_=15, thresh_=(0.7, 1.3))\n",
    "\n",
    "test_combine_sobel = sobel_complex_combine(test_colorSelect)\n",
    "\n",
    "\n",
    "# Display\n",
    "f1, (a11, a12) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f1.tight_layout()\n",
    "a11.imshow(test_img)\n",
    "a11.set_title('Original Image', fontsize=50)\n",
    "a12.imshow(test_combine_sobel, cmap='gray')\n",
    "a12.set_title('Complex Combined', fontsize=50)\n",
    "\n",
    "f2, (a21, a22) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f2.tight_layout()\n",
    "a21.imshow(test_abs_sobelx, cmap='gray')\n",
    "a21.set_title('Abs SobelX', fontsize=50)\n",
    "a22.imshow(test_abs_sobely, cmap='gray')\n",
    "a22.set_title('Abs SobelY', fontsize=50)\n",
    "\n",
    "f3, (a31, a32) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f3.tight_layout()\n",
    "a31.imshow(test_mag_sobel, cmap='gray')\n",
    "a31.set_title('Sobel Mag', fontsize=50)\n",
    "a32.imshow(test_dir_sobel, cmap='gray')\n",
    "a32.set_title('Sobel Dir', fontsize=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color and Sobel Thresholding Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combine_threshold(color_thresh_, combine_sobel_):    \n",
    "    # Stack each channel to view their individual contributions in green and blue respectively     \n",
    "    color_binary = np.dstack(( np.zeros_like(color_thresh_),\n",
    "                               combine_sobel_,\n",
    "                               color_thresh_ ))\n",
    "    color_binary[color_binary > 0.5] = 255  #help plotting of rgb\n",
    "    \n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(color_thresh_)\n",
    "    combined_binary[(color_thresh_ == 1) | (combine_sobel_ == 1)] = 1\n",
    "    \n",
    "    return color_binary, combined_binary\n",
    "\n",
    "\n",
    "'''\n",
    "run it...\n",
    "'''\n",
    "color_binary, combined_binary = combine_threshold(test_color_thresh, test_combine_sobel)\n",
    "\n",
    "# Plotting thresholded images\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.set_title('Stacked thresholds (green=sobelx, blue=s_channel)')\n",
    "ax1.imshow(color_binary)\n",
    "ax2.set_title('Combined S-channel and Sobel thresholds')\n",
    "ax2.imshow(combined_binary, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "warp_src = np.float32([[0,0],[0,0],[0,0],[0,0]])\n",
    "warp_dst = np.float32([[0,0],[0,0],[0,0],[0,0]])\n",
    "\n",
    "X_INDEX = 0\n",
    "Y_INDEX = 1\n",
    "\n",
    "def update_warp_points(img_):\n",
    "    global warp_src\n",
    "    global warp_dst\n",
    "    \n",
    "    height = img_.shape[0]\n",
    "    width  = img_.shape[1]\n",
    "        \n",
    "    #top_left\n",
    "    warp_src[0,X_INDEX] = width*0.435 \n",
    "    warp_src[0,Y_INDEX] = height*0.65  \n",
    "    #top_right\n",
    "    warp_src[1,X_INDEX] = width*0.575\n",
    "    warp_src[1,Y_INDEX] = height*0.65\n",
    "    #bottom_left\n",
    "    warp_src[2,X_INDEX] = width*0.165 \n",
    "    warp_src[2,Y_INDEX] = height*0.99\n",
    "    #bottom_right\n",
    "    warp_src[3,X_INDEX] = width*0.875\n",
    "    warp_src[3,Y_INDEX] = height*0.99\n",
    "\n",
    "    #top_left\n",
    "    warp_dst[0,X_INDEX] = width*0.35 \n",
    "    warp_dst[0,Y_INDEX] = height*0.01    \n",
    "    #top_right\n",
    "    warp_dst[1,X_INDEX] = width*0.65 \n",
    "    warp_dst[1,Y_INDEX] = height*0.01\n",
    "    #bottom_left\n",
    "    warp_dst[2,X_INDEX] = width*0.35 \n",
    "    warp_dst[2,Y_INDEX] = height*0.99\n",
    "    #bottom_right\n",
    "    warp_dst[3,X_INDEX] = width*0.65 \n",
    "    warp_dst[3,Y_INDEX] = height*0.99\n",
    "    \n",
    "    \n",
    "def perspective_warp(img_):\n",
    "    update_warp_points(img_)\n",
    "        \n",
    "    img_size = (img_.shape[1], img_.shape[0])\n",
    "    M = cv2.getPerspectiveTransform(warp_src, warp_dst)\n",
    "    return cv2.warpPerspective(img_, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "def perspective_warp_inv(img_):\n",
    "    update_warp_points(img_)\n",
    "    \n",
    "    img_size = (img_.shape[1], img_.shape[0])\n",
    "    Minv = cv2.getPerspectiveTransform(warp_dst, warp_src)\n",
    "    return cv2.warpPerspective(img_, Minv, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "'''\n",
    "run it...\n",
    "'''\n",
    "# Example of Perspective Transform\n",
    "pTrans_img = mpimg.imread('test_images/solidWhiteRight.jpg')\n",
    "pTrans_warped = perspective_warp(pTrans_img)\n",
    "\n",
    "\n",
    "# Plotting transformed image\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(20,10))\n",
    "\n",
    "ax1.set_title('Original: Marked Src Points')\n",
    "ax1.imshow(pTrans_img)\n",
    "ax1.plot(warp_src[0,0],warp_src[0,1],'.')  #top left\n",
    "ax1.plot(warp_src[1,0],warp_src[1,1],'.')  #top right\n",
    "ax1.plot(warp_src[2,0],warp_src[2,1],'.')  #bottom left\n",
    "ax1.plot(warp_src[3,0],warp_src[3,1],'.')  #bottom right\n",
    "\n",
    "ax2.set_title('Perspective Transform: Marked Dst Points')\n",
    "ax2.imshow(pTrans_warped)\n",
    "ax2.plot(warp_dst[0,0],warp_dst[0,1],'.')  #top left\n",
    "ax2.plot(warp_dst[1,0],warp_dst[1,1],'.')  #top right\n",
    "ax2.plot(warp_dst[2,0],warp_dst[2,1],'.')  #bottom left\n",
    "ax2.plot(warp_dst[3,0],warp_dst[3,1],'.')  #bottom right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Region of Interest:\n",
    "Goal: Only keep marker that are in the center\n",
    "\"\"\"\n",
    "def region_of_interest(img_, vertices_):\n",
    "    \"\"\"\n",
    "    Applies an image mask:    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img_)       \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img_.shape) > 2:\n",
    "        channel_count = img_.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices_, ignore_mask_color)    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img_, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def hk_region_ofInterest(img_):\n",
    "    height = img_.shape[0]\n",
    "    width  = img_.shape[1]\n",
    "    \n",
    "    height_mult  = 0.60\n",
    "    width_mult_R = 0.54\n",
    "    width_mult_L = 0.44\n",
    "    \n",
    "    # [horiz, vert]\n",
    "    top_left     = [width*width_mult_L, height*height_mult]\n",
    "    top_right    = [width*width_mult_R, height*height_mult]\n",
    "    bottom_right = [width, height]\n",
    "    bottom_left  = [0, height]\n",
    "    \n",
    "    poly = np.array([top_left, top_right, bottom_right, bottom_left], np.int32)\n",
    "    return region_of_interest(img_, [poly])\n",
    "\n",
    "\n",
    "'''\n",
    "run it...\n",
    "''' \n",
    "test_img_roi = hk_region_ofInterest(combined_binary)\n",
    "\n",
    "# Display the image\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.set_title('Original Image')\n",
    "ax1.imshow(test_img)\n",
    "\n",
    "ax2.set_title('Region of Interest')\n",
    "ax2.imshow(test_img_roi, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find points on line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_BANDS = 20 #10\n",
    "TRACK_THRESHOLD = 10 #20\n",
    "BOX_HALF_WIDTH = 50\n",
    "\n",
    "# Find point in histogram and add to list\n",
    "def find_point(histogram_, avg_height_, is_initialized_, min_edge_, max_edge_, last_center_, list_):\n",
    "    # decide width to look in for max\n",
    "    if is_initialized_ == True:\n",
    "        left_edge = last_center_ - BOX_HALF_WIDTH\n",
    "        right_edge = last_center_ + BOX_HALF_WIDTH            \n",
    "    else:\n",
    "        left_edge = min_edge_\n",
    "        right_edge = max_edge_\n",
    "\n",
    "    # find the max\n",
    "    center_guess = np.argmax(histogram_[left_edge:right_edge])+left_edge\n",
    "    center_value = histogram_[center_guess]\n",
    "    if center_value > TRACK_THRESHOLD:\n",
    "        list_.append((center_guess, avg_height_))\n",
    "        last_center_ = center_guess\n",
    "        if is_initialized_ == False:\n",
    "            is_initialized_ = True\n",
    "\n",
    "    return is_initialized_, last_center_, list_\n",
    "\n",
    "\n",
    "# Find points on the lane lines\n",
    "def get_lane_points(img_):\n",
    "    left = []\n",
    "    right = []\n",
    "    \n",
    "    #band_start = img_.shape[0]\n",
    "    band_depth = int(img_.shape[0]/NUM_BANDS)\n",
    "    \n",
    "    tops = np.arange(0, img_.shape[0]-1, band_depth)\n",
    "    bottoms = tops + (band_depth-1)\n",
    "    \n",
    "    # reverse the arrays\n",
    "    tops = tops[::-1]\n",
    "    bottoms = bottoms[::-1]\n",
    "    \n",
    "    is_left_initialized = False\n",
    "    is_right_initialized = False\n",
    "    last_left_center = 0\n",
    "    last_right_center = 0\n",
    "    \n",
    "    for index in range(len(tops)):\n",
    "        histogram = np.sum(img_[tops[index]:bottoms[index],:], axis=0)\n",
    "        hist_len = histogram.shape[0]\n",
    "        avg_height = (tops[index] + bottoms[index])/2\n",
    "\n",
    "        is_left_initialized, last_left_center, left = find_point(histogram,\n",
    "                                                                 avg_height,\n",
    "                                                                 is_left_initialized, \n",
    "                                                                 0, \n",
    "                                                                 int(hist_len/2), \n",
    "                                                                 last_left_center, \n",
    "                                                                 left)       \n",
    "        is_right_initialized, last_right_center, right = find_point(histogram,\n",
    "                                                                 avg_height,\n",
    "                                                                 is_right_initialized, \n",
    "                                                                 int(hist_len/2), \n",
    "                                                                 hist_len-1, \n",
    "                                                                 last_right_center, \n",
    "                                                                 right)\n",
    "    return left, right\n",
    "\n",
    "\n",
    "# Display points\n",
    "def add_points(fig_, points_, marking_):\n",
    "    for pt_tuple in points_:\n",
    "        fig_.plot(pt_tuple[0],pt_tuple[1],marking_, markersize=30)\n",
    "\n",
    "\n",
    "'''\n",
    "run it...\n",
    "'''\n",
    "test_warped = perspective_warp(test_img_roi)\n",
    "left_pts, right_pts = get_lane_points(test_warped)\n",
    "\n",
    "# Display the image\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(20,10))\n",
    "ax1.set_title('Original: Marked Lane Points')\n",
    "ax1.imshow(test_warped, cmap='gray')\n",
    "add_points(ax1, left_pts, 'b.')\n",
    "add_points(ax1, right_pts, 'r.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curve Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line:\n",
    "    def __init__(self, alpha_, num_output_pts_, img_height_):\n",
    "        # constants\n",
    "        self._alpha = alpha_\n",
    "        self._num_output_pts = num_output_pts_\n",
    "        self._img_height = img_height_\n",
    "        \n",
    "        # variables\n",
    "        self._yMin = img_height_\n",
    "        self._tracked_pts = {}  #dict of key=yVal, value=xVal\n",
    "        self._fit_coeff = [np.array([False])]\n",
    "        self._radius_of_curv = None\n",
    "        return\n",
    "    \n",
    "    # points_ = list of (x,y) tuples\n",
    "    def _update_pts(self, points_):\n",
    "        for (xVal, yVal) in points_:\n",
    "            if yVal in self._tracked_pts:\n",
    "                # first-order low-pass filter\n",
    "                self._tracked_pts[yVal] = (1-self._alpha)*self._tracked_pts[yVal] \\\n",
    "                                          + self._alpha*xVal\n",
    "            else:\n",
    "                self._tracked_pts[yVal] = xVal\n",
    "        return\n",
    "\n",
    "    def _calc_curvature(self):\n",
    "        # f(y) = Ay^2 + By + C\n",
    "        A = self._fit_coeff[0]\n",
    "        B = self._fit_coeff[1]\n",
    "        y = self._img_height\n",
    "        \n",
    "        # R = (1+(2Ay+B)^2)^1.5/abs(2A)\n",
    "        self._radius_of_curv = ((1 + (2*A*y + B)**2)**1.5) \\\n",
    "                             /np.absolute(2*A) \n",
    "        \n",
    "        #TODO: convert to meters\n",
    "    \n",
    "    def _fit_curve(self):\n",
    "        # get x and y values\n",
    "        x_list = []\n",
    "        y_list = []\n",
    "        for key, value in self._tracked_pts.items():\n",
    "            x_list.append(value)\n",
    "            y_list.append(key)\n",
    "        x_vals = np.asarray(x_list)\n",
    "        y_vals = np.asarray(y_list)\n",
    "        \n",
    "        self._yMin = min(y_vals)\n",
    "        \n",
    "        # Fit a second order polynomial (fit_coeff[0]*y**2 + fit_coeff[1]*y + fit_coeff[2])\n",
    "        self._fit_coeff = np.polyfit(y_vals, x_vals, 2)\n",
    "        \n",
    "        # calc curvature\n",
    "        self._calc_curvature()\n",
    "\n",
    "    \n",
    "    '''\n",
    "    External API\n",
    "    '''\n",
    "    def update(self, points_):\n",
    "        self._update_pts(points_)\n",
    "        self._fit_curve()\n",
    "    \n",
    "    @property\n",
    "    def yMin(self):\n",
    "        return self._yMin\n",
    "    \n",
    "    def gen_curve_pts(self, y_min_):\n",
    "        self._yGen = np.linspace(y_min_, self._img_height-1, num=self._num_output_pts)\n",
    "        self._xGen = self._fit_coeff[0]*self._yGen**2 \\\n",
    "                   + self._fit_coeff[1]*self._yGen \\\n",
    "                   + self._fit_coeff[2]\n",
    "                \n",
    "    @property\n",
    "    def xGen(self):\n",
    "        return self._xGen\n",
    "    \n",
    "    @property\n",
    "    def yGen(self):\n",
    "        return self._yGen\n",
    "    \n",
    "    @property\n",
    "    def radius_of_curv(self):\n",
    "        return self._radius_of_curv\n",
    "        \n",
    "'''\n",
    "test it...\n",
    "'''\n",
    "test_height = test_img.shape[0]\n",
    "fake_line = Line(0.5, 10, test_height)\n",
    "\n",
    "fake_line.update(right_pts)\n",
    "print('y_min = {}'.format(fake_line.yMin))\n",
    "fake_line.gen_curve_pts(fake_line.yMin)\n",
    "print('xGen = {}'.format(fake_line.xGen))\n",
    "\n",
    "print('')\n",
    "\n",
    "fake_line.update(left_pts)\n",
    "print('y_min = {}'.format(fake_line.yMin))\n",
    "fake_line.gen_curve_pts(fake_line.yMin)\n",
    "print('xGen = {}'.format(fake_line.xGen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# give new points to the line classes\n",
    "def update_lines(left_line_, right_line_, left_pts_, right_pts_):\n",
    "    left_line_.update(left_pts_)\n",
    "    right_line_.update(right_pts_)\n",
    "\n",
    "    test_yMin = min(left_line_.yMin, right_line_.yMin)\n",
    "    left_line_.gen_curve_pts(test_yMin)\n",
    "    right_line_.gen_curve_pts(test_yMin)    \n",
    "    return left_line_, right_line_\n",
    "\n",
    "\n",
    "# Display curve on figure\n",
    "def add_curve(fig_, x_fit_, y_vals_):\n",
    "    fig_.plot(x_fit_, y_vals_, color='green', linewidth=3)\n",
    "\n",
    "\n",
    "'''\n",
    "run it...\n",
    "'''\n",
    "LINE_ALPHA = 0.5\n",
    "LINE_NUM_PTS = 10\n",
    "TEST_HEIGHT = test_img.shape[0]\n",
    "\n",
    "test_left_line  = Line(LINE_ALPHA, LINE_NUM_PTS, TEST_HEIGHT)\n",
    "test_right_line = Line(LINE_ALPHA, LINE_NUM_PTS, TEST_HEIGHT)\n",
    "\n",
    "test_left_line, test_right_line = update_lines(test_left_line,\n",
    "                                               test_right_line, \n",
    "                                               left_pts,\n",
    "                                               right_pts)\n",
    "\n",
    "# Display the image\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(20,10))\n",
    "ax1.set_title('Original: Marked Lane Points')\n",
    "ax1.imshow(test_warped, cmap='gray')\n",
    "add_points(ax1, left_pts, 'b.')\n",
    "add_points(ax1, right_pts, 'r.')\n",
    "add_curve(ax1, test_left_line.xGen, test_left_line.yGen)\n",
    "add_curve(ax1, test_right_line.xGen, test_right_line.yGen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def path_overlay(rgb_img_, left_fitx_, left_yvals_, right_fitx_, right_yvals_):\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(rgb_img_[:,:,0]).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx_, left_yvals_]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx_, right_yvals_])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    return cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "\n",
    "'''\n",
    "run it...\n",
    "'''\n",
    "# generate overlays\n",
    "overlay_warped = path_overlay(test_img, test_left_line.xGen, test_left_line.yGen, \n",
    "                                        test_right_line.xGen, test_right_line.yGen)\n",
    "overlay_unwarped = perspective_warp_inv(overlay_warped)\n",
    "\n",
    "# put overlays on images\n",
    "test_warped_rgb = perspective_warp(test_img)\n",
    "test_warped_marked = cv2.addWeighted(test_warped_rgb, 1, overlay_warped, 0.3, 0)\n",
    "test_img_marked = cv2.addWeighted(test_img, 1, overlay_unwarped, 0.3, 0)\n",
    "\n",
    "\n",
    "# Display the image\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.set_title('Overlay in Warped Image')\n",
    "ax1.imshow(test_warped_marked)\n",
    "ax2.set_title('Overlay in Original Image')\n",
    "ax2.imshow(test_img_marked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEXT_FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "TEXT_SIZE = 1.5\n",
    "TEXT_COLOR = (255,255,255)\n",
    "TEXT_THICKNESS = 5\n",
    "\n",
    "def avg_curvature(left_curvature_, right_curvature_):\n",
    "    return (left_curvature_ + right_curvature_)/2\n",
    "\n",
    "def display_curvature(img_, left_line_, right_line_):\n",
    "    # calculate curvature\n",
    "    avg_curv = avg_curvature(left_line_.radius_of_curv, \n",
    "                             right_line_.radius_of_curv)\n",
    "    string_curv = \"radius of curvature = \" + str(int(avg_curv))\n",
    "\n",
    "    # put text on image\n",
    "    CURVATURE_TEXT_POSITION = (50,75)\n",
    "    text_curv = np.copy(img_)\n",
    "    return cv2.putText(text_curv, string_curv, CURVATURE_TEXT_POSITION, \n",
    "                         TEXT_FONT, TEXT_SIZE, TEXT_COLOR, TEXT_THICKNESS)\n",
    "\n",
    "'''\n",
    "run it...\n",
    "'''\n",
    "test_text_curv = display_curvature(test_img_marked, test_left_line, test_right_line)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(test_text_curv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_image(image_, left_line_, right_line_, num_overlay_pts_=10):\n",
    "    \n",
    "    # color selection\n",
    "    img_cs = color_select(image_)\n",
    "    \n",
    "    # color transform and threshold\n",
    "    color_thresh = threshold_color(rgb_to_s(img_cs), \n",
    "                                    MIN_COLOR_THRESHOLD, \n",
    "                                    MAX_COLOR_THRESHOLD)\n",
    "    \n",
    "    # sobel transform and threshold\n",
    "    combine_sobel = sobel_complex_combine(img_cs)\n",
    "    \n",
    "    # Combine color and sobel\n",
    "    _, combined_binary = combine_threshold(color_thresh, combine_sobel)\n",
    "    \n",
    "    # Mask region of interest\n",
    "    img_roi = hk_region_ofInterest(combined_binary)\n",
    "    \n",
    "    # Perspective Transform\n",
    "    img_warped = perspective_warp(img_roi)\n",
    "    \n",
    "    # Grab points from image\n",
    "    left_points, right_points = get_lane_points(img_warped)\n",
    "    \n",
    "    # Update line classes\n",
    "    left_line_, right_line_ = update_lines(left_line_, right_line_, \n",
    "                                           left_points, right_points)\n",
    "    \n",
    "    # generate overlays\n",
    "    warped_overlay = path_overlay(image_, left_line_.xGen, left_line_.yGen, \n",
    "                                          right_line_.xGen, right_line.yGen)\n",
    "    unwarped_overlay = perspective_warp_inv(warped_overlay)\n",
    "\n",
    "    # put overlays on images\n",
    "    img_weighted = cv2.addWeighted(image_, 1, unwarped_overlay, 0.3, 0)\n",
    "\n",
    "    text_curv = display_curvature(img_weighted, left_line_, right_line_)\n",
    "    return text_curv\n",
    "\n",
    "print('Success: process_image() function defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "is_left = True\n",
    "img_names = os.listdir('test_images/')\n",
    "\n",
    "for index, name in enumerate(img_names):\n",
    "    image = mpimg.imread('test_images/' + name)\n",
    "    \n",
    "    SINGLE_FRAME_HEIGHT = image.shape[0]\n",
    "    left_line  = Line(LINE_ALPHA, LINE_NUM_PTS, SINGLE_FRAME_HEIGHT)\n",
    "    right_line = Line(LINE_ALPHA, LINE_NUM_PTS, SINGLE_FRAME_HEIGHT)\n",
    "    \n",
    "    image = process_image(image, left_line, right_line)\n",
    "    if is_left:\n",
    "        fig = plt.figure(figsize=(8, 6))\n",
    "        a=fig.add_subplot(1,2,1)\n",
    "        is_left = False\n",
    "    else:    \n",
    "        a=fig.add_subplot(1,2,2)\n",
    "        is_left = True\n",
    "    a.set_title(name)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# VideoProcessor Class\n",
    "\n",
    "class VideoProcessor:\n",
    "    def __init__(self, alpha_, num_output_pts_, img_height_):\n",
    "        self._left_line = Line(alpha_, num_output_pts_, img_height_)\n",
    "        self._right_line = Line(alpha_, num_output_pts_, img_height_)\n",
    "    \n",
    "    '''\n",
    "    External API\n",
    "    '''\n",
    "    def process_images_multiple(self, image_):\n",
    "        return process_image(image_, self._left_line, self._right_line)\n",
    "\n",
    "    \n",
    "print('Success: VideoProcessor class defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "def process_video(input_filename_, output_filename_):\n",
    "    # Grab the video\n",
    "    clip = VideoFileClip(input_filename_)\n",
    "    first_frame = clip.get_frame(0)\n",
    "    \n",
    "    # Process the frames\n",
    "    VIDEO_HEIGHT = first_frame.shape[0]\n",
    "    video_processor = VideoProcessor(LINE_ALPHA, LINE_NUM_PTS, VIDEO_HEIGHT)\n",
    "    processed_clip = clip.fl_image(video_processor.process_images_multiple) #NOTE: this function expects color images!!\n",
    "\n",
    "    # Save the video\n",
    "    %time processed_clip.write_videofile(output_filename_, audio=False)\n",
    "\n",
    "    \n",
    "print('Success: process_video() function defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "process_video('project_video.mp4', 'project_soln.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('project_soln.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "process_video('challenge_video.mp4', 'challenge_soln.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('challenge_soln.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Harder Challenge Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "process_video('harder_challenge_video.mp4', 'harder_challenge_soln.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('harder_challenge_soln.mp4'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
