{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Advanced Lane Finding** \n",
    "\n",
    "---\n",
    "By Hasan Korre\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply the distortion correction to the raw image.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find lane boundary.\n",
    "* Determine curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration (Distortion Correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "# Read in a calibration image\n",
    "img = mpimg.imread('camera_cal/calibration2.jpg')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corner Detection for 1 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Arrays to store object points and image points from all the images\n",
    "obj_points = []  #3D points in real world space\n",
    "img_points = []  #2D point in image plane\n",
    "\n",
    "# Prepare object points, like (0,0,0), (1,0,0), (2,0,0), (8,5,0)\n",
    "nx = 9  #num of inside corners in x\n",
    "ny = 6  #num of inside corners in y\n",
    "objp = np.zeros((ny*nx,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Convert image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Find the chessboard corners\n",
    "ret, corners = cv2.findChessboardCorners(gray,(nx, ny), None)\n",
    "\n",
    "# If corners are found, add object points and image points\n",
    "if ret == True:\n",
    "    img_points.append(corners)\n",
    "    obj_points.append(objp)\n",
    "    \n",
    "    # Draw and display the corners\n",
    "    cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "    plt.imshow(img)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrate the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Read in and make a list of calibration image\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Arrays to store object points and image points from all the images\n",
    "obj_points = []  #3D points in real world space\n",
    "img_points = []  #2D point in image plane\n",
    "\n",
    "# Prepare object points, like (0,0,0), (1,0,0), (2,0,0), (8,5,0)\n",
    "nx = 9  #num of inside corners in x\n",
    "ny = 6  #num of inside corners in y\n",
    "objp = np.zeros((ny*nx,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "for filename in images:\n",
    "    # read in each image\n",
    "    img = mpimg.imread(filename)\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray,(nx, ny), None)\n",
    "\n",
    "    # If corners are found, add object points and image points\n",
    "    if ret == True:\n",
    "        img_points.append(corners)\n",
    "        obj_points.append(objp)\n",
    "\n",
    "# Calibrate the camera\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(obj_points, img_points, img_size, None, None)\n",
    "\n",
    "print('Success: Calibrated camera.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undistort an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Undistortion function\n",
    "#   mtx_  = camera matrix\n",
    "#   dist_ = distortion coefficients\n",
    "def cal_undistort(img_, mtx_, dist_):\n",
    "    return cv2.undistort(img_, mtx_, dist_, None, mtx_)\n",
    "\n",
    "# Test\n",
    "img_original = mpimg.imread('camera_cal/calibration5.jpg')\n",
    "img_undistort = cal_undistort(img_original, mtx, dist)\n",
    "\n",
    "# Display\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img_original)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(img_undistort)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a thresholded binary image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Color transforms and SobelX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert to HLS color space and separate the S channel\n",
    "def rgb_to_s(img_):   \n",
    "    hls = cv2.cvtColor(img_, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    return s_channel\n",
    "\n",
    "# RBG to Grayscale\n",
    "def rbg_to_gray(img_):\n",
    "    return cv2.cvtColor(img_, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Get X gradient through sobelx operator\n",
    "# ksize â€“ size of the extended Sobel kernel; it must be 1, 3, 5, or 7\n",
    "def sobelx(img_, kernel_=3):\n",
    "    gray = rbg_to_gray(img_)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=kernel_) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    #rescaling to 8-bit\n",
    "    scale_factor = np.max(abs_sobelx)/255\n",
    "    return (abs_sobelx/scale_factor).astype(np.uint8)\n",
    "\n",
    "print('Success: Color transform and SobelX functions defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "# Example Color Transform\n",
    "test_img = mpimg.imread('test_images/test4.jpg')\n",
    "test_sChannel = rgb_to_s(test_img)\n",
    "\n",
    "# Display\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(test_img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(test_sChannel, cmap='gray')\n",
    "ax2.set_title('S-Channel Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Example Sobelx Transform\n",
    "test_img = mpimg.imread('test_images/test4.jpg')\n",
    "test_sobelx = sobelx(test_img, 3)\n",
    "\n",
    "# Display\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(test_img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(test_sobelx, cmap='gray')\n",
    "ax2.set_title('SobelX Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Threshold color channel\n",
    "def threshold_color(img_channel_, s_thresh_min_, s_thresh_max_):\n",
    "    s_binary = np.zeros_like(img_channel_)\n",
    "    s_binary[(img_channel_ >= s_thresh_min_) & (img_channel_ <= s_thresh_max_)] = 1\n",
    "    return s_binary\n",
    "\n",
    "# Threshold x gradient\n",
    "def threshold_xGradient(img_sobel_, thresh_min_, thresh_max_):\n",
    "    sxbinary = np.zeros_like(img_sobel_)\n",
    "    sxbinary[(img_sobel_ >= thresh_min_) & (img_sobel_ <= thresh_max_)] = 1\n",
    "    return sxbinary\n",
    "\n",
    "print('Success: Thresholding functions defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "# Example Color Thresholding\n",
    "test_img = mpimg.imread('test_images/test4.jpg')\n",
    "test_sChannel = rgb_to_s(test_img)\n",
    "test_color_thresh = threshold_color(test_sChannel, 170, 255)\n",
    "\n",
    "# Display\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(test_sChannel, cmap='gray')\n",
    "ax1.set_title('S-Channel Image', fontsize=50)\n",
    "ax2.imshow(test_color_thresh, cmap='gray')\n",
    "ax2.set_title('Thresholded S-Channel Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "# Example X-Gradient Thresholding\n",
    "test_img = mpimg.imread('test_images/test4.jpg')\n",
    "test_sobelx = sobelx(test_img, 3)\n",
    "test_sobelx_thresh = threshold_xGradient(test_sobelx, 20, 100)\n",
    "\n",
    "# Display\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(test_sobelx, cmap='gray')\n",
    "ax1.set_title('SobelX Image', fontsize=50)\n",
    "ax2.imshow(test_sobelx_thresh, cmap='gray')\n",
    "ax2.set_title('Thresholded SobelX Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel and Color Thresholding Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def combine_threshold(img_):\n",
    "    # Color Thresholding\n",
    "    sChannel_img = rgb_to_s(img_)\n",
    "    color_thresh = threshold_color(sChannel_img, 170, 255)\n",
    "    \n",
    "    # Example X-Gradient Thresholding\n",
    "    sobelx_img = sobelx(img_, 3)\n",
    "    sobelx_thresh = threshold_xGradient(sobelx_img, 20, 100)\n",
    "    \n",
    "    # Stack each channel to view their individual contributions in green and blue respectively\n",
    "    # This returns a stack of the two binary images, whose components you can see as different colors\n",
    "    color_binary = np.dstack(( np.zeros_like(sobelx_thresh),\n",
    "                               sobelx_thresh,\n",
    "                               color_thresh ))\n",
    "    color_binary[color_binary > 0.5] = 255  #help plotting of rgb\n",
    "    \n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(sobelx_thresh)\n",
    "    combined_binary[(sobelx_thresh == 1) | (color_thresh == 1)] = 1\n",
    "    \n",
    "    return color_binary, combined_binary\n",
    "\n",
    "\n",
    "test_img = mpimg.imread('test_images/test4.jpg')\n",
    "color_binary, combined_binary = combine_threshold(test_img)\n",
    "\n",
    "\n",
    "# Plotting thresholded images\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.set_title('Stacked thresholds (green=sobelx, blue=s_channel)')\n",
    "ax1.imshow(color_binary)\n",
    "\n",
    "ax2.set_title('Combined S channel and gradient thresholds')\n",
    "ax2.imshow(combined_binary, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "warp_src = np.float32([[0,0],[0,0],[0,0],[0,0]])\n",
    "\n",
    "warp_dst = np.float32([[0,0],[0,0],[0,0],[0,0]])\n",
    "\n",
    "X_INDEX = 0\n",
    "Y_INDEX = 1\n",
    "\n",
    "def update_warp_points(img_):\n",
    "    global warp_src\n",
    "    global warp_dst\n",
    "    \n",
    "    height = img_.shape[0]\n",
    "    width  = img_.shape[1]\n",
    "        \n",
    "    #top_left\n",
    "    warp_src[0,X_INDEX] = width*0.4725 \n",
    "    warp_src[0,Y_INDEX] = height*0.60  \n",
    "    #top_right\n",
    "    warp_src[1,X_INDEX] = width*0.53 \n",
    "    warp_src[1,Y_INDEX] = height*0.60\n",
    "    #bottom_left\n",
    "    warp_src[2,X_INDEX] = width*0.17 \n",
    "    warp_src[2,Y_INDEX] = height*0.99\n",
    "    #bottom_right\n",
    "    warp_src[3,X_INDEX] = width*0.875\n",
    "    warp_src[3,Y_INDEX] = height*0.99\n",
    "\n",
    "    #top_left\n",
    "    warp_dst[0,X_INDEX] = width*0.35 \n",
    "    warp_dst[0,Y_INDEX] = height*0.01    \n",
    "    #top_right\n",
    "    warp_dst[1,X_INDEX] = width*0.65 \n",
    "    warp_dst[1,Y_INDEX] = height*0.01\n",
    "    #bottom_left\n",
    "    warp_dst[2,X_INDEX] = width*0.35 \n",
    "    warp_dst[2,Y_INDEX] = height*0.99\n",
    "    #bottom_right\n",
    "    warp_dst[3,X_INDEX] = width*0.65 \n",
    "    warp_dst[3,Y_INDEX] = height*0.99\n",
    "    \n",
    "    \n",
    "def perspective_warp(img_):\n",
    "    update_warp_points(img_)\n",
    "        \n",
    "    img_size = (img_.shape[1], img_.shape[0])\n",
    "    M = cv2.getPerspectiveTransform(warp_src, warp_dst)\n",
    "    return cv2.warpPerspective(img_, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "def perspective_warp_inv(img_):\n",
    "    update_warp_points(img_)\n",
    "    \n",
    "    img_size = (img_.shape[1], img_.shape[0])\n",
    "    Minv = cv2.getPerspectiveTransform(warp_dst, warp_src)\n",
    "    return cv2.warpPerspective(img_, Minv, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "print('Success: Perspective Transform functions defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "# Example of Perspective Transform\n",
    "test_img = mpimg.imread('test_images/solidWhiteRight.jpg')\n",
    "#test_img = mpimg.imread('test_images/test5.jpg')\n",
    "warped = perspective_warp(test_img)\n",
    "\n",
    "\n",
    "# Plotting transformed image\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(20,10))\n",
    "ax1.set_title('Original: Marked Src Points')\n",
    "ax1.imshow(test_img)\n",
    "\n",
    "ax1.plot(warp_src[0,0],warp_src[0,1],'.')  #top left\n",
    "ax1.plot(warp_src[1,0],warp_src[1,1],'.')  #top right\n",
    "ax1.plot(warp_src[2,0],warp_src[2,1],'.')  #bottom left\n",
    "ax1.plot(warp_src[3,0],warp_src[3,1],'.')  #bottom right\n",
    "\n",
    "\n",
    "ax2.set_title('Perspective Transform: Marked Dst Points')\n",
    "ax2.imshow(warped)\n",
    "ax2.plot(warp_dst[0,0],warp_dst[0,1],'.')  #top left\n",
    "ax2.plot(warp_dst[1,0],warp_dst[1,1],'.')  #top right\n",
    "ax2.plot(warp_dst[2,0],warp_dst[2,1],'.')  #bottom left\n",
    "ax2.plot(warp_dst[3,0],warp_dst[3,1],'.')  #bottom right\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "\"\"\"\n",
    "Region of Interest:\n",
    "Goal: Only keep marker that are in the center\n",
    "\"\"\"\n",
    "\n",
    "def region_of_interest(img_, vertices_):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img_)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img_.shape) > 2:\n",
    "        channel_count = img_.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices_, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img_, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def hk_region_ofInterest(img_):\n",
    "    height = img_.shape[0]\n",
    "    width  = img_.shape[1]\n",
    "    \n",
    "    height_mult  = 0.60\n",
    "    width_mult_R = 0.54\n",
    "    width_mult_L = 0.44\n",
    "    \n",
    "    # [horiz, vert]\n",
    "    top_left     = [width*width_mult_L, height*height_mult]\n",
    "    top_right    = [width*width_mult_R, height*height_mult]\n",
    "    bottom_right = [width, height]\n",
    "    bottom_left  = [0, height]\n",
    "    \n",
    "    poly = np.array([top_left, top_right, bottom_right, bottom_left], np.int32)\n",
    "    return region_of_interest(img_, [poly])\n",
    "\n",
    "'''\n",
    "run it...\n",
    "'''  \n",
    "test_img = mpimg.imread('test_images/test5.jpg')\n",
    "\n",
    "# transforms\n",
    "_, combined_binary = combine_threshold(test_img)\n",
    "test_img_roi = hk_region_ofInterest(combined_binary)\n",
    "\n",
    "# Display the image\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.set_title('Original Image')\n",
    "ax1.imshow(test_img)\n",
    "\n",
    "ax2.set_title('Region of Interest')\n",
    "ax2.imshow(test_img_roi, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find points on line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#test_img = mpimg.imread('test_images/solidWhiteRight.jpg')\n",
    "test_img = mpimg.imread('test_images/test5.jpg')\n",
    "\n",
    "# transforms\n",
    "_, combined_binary = combine_threshold(test_img)\n",
    "test_img_roi = hk_region_ofInterest(combined_binary)\n",
    "test_warped = perspective_warp(test_img_roi)\n",
    "\n",
    "NUM_BANDS = 10\n",
    "TRACK_THRESHOLD = 20\n",
    "BOX_HALF_WIDTH = 50\n",
    "\n",
    "def find_point(histogram_, avg_height_, is_initialized_, min_edge_, max_edge_, last_center_, list_):\n",
    "    # decide width to look in for max\n",
    "    if is_initialized_ == True:\n",
    "        left_edge = last_center_ - BOX_HALF_WIDTH\n",
    "        right_edge = last_center_ + BOX_HALF_WIDTH            \n",
    "    else:\n",
    "        left_edge = min_edge_\n",
    "        right_edge = max_edge_\n",
    "\n",
    "    #print('\\t(L_edge,R_edge)=({},{})'.format(left_edge, right_edge))\n",
    "    # find the max\n",
    "    center_guess = np.argmax(histogram_[left_edge:right_edge])+left_edge\n",
    "    center_value = histogram_[center_guess]\n",
    "    #print('\\tcenter_guess: ', center_guess)\n",
    "    #print('\\tcenter_value: ', center_value)\n",
    "    if center_value > TRACK_THRESHOLD:\n",
    "        #print('\\tappending...')\n",
    "        list_.append((center_guess, avg_height_))\n",
    "        last_center_ = center_guess\n",
    "        if is_initialized_ == False:\n",
    "            is_initialized_ = True\n",
    "\n",
    "    return is_initialized_, last_center_, list_\n",
    "\n",
    "\n",
    "def get_lane_points(img_):\n",
    "    left = []\n",
    "    right = []\n",
    "    \n",
    "\n",
    "    #band_start = img_.shape[0]\n",
    "    band_depth = int(img_.shape[0]/NUM_BANDS)\n",
    "    \n",
    "    tops = np.arange(0, img_.shape[0]-1, band_depth)\n",
    "    bottoms = tops + (band_depth-1)\n",
    "    \n",
    "    # reverse the arrays\n",
    "    tops = tops[::-1]\n",
    "    bottoms = bottoms[::-1]\n",
    "    \n",
    "    is_left_initialized = False\n",
    "    is_right_initialized = False\n",
    "    last_left_center = 0\n",
    "    last_right_center = 0\n",
    "    \n",
    "    for index in range(len(tops)):\n",
    "        #print('(top, bottom)=({},{})'.format(tops[index], bottoms[index]))\n",
    "        histogram = np.sum(img_[tops[index]:bottoms[index],:], axis=0)\n",
    "        hist_len = histogram.shape[0]\n",
    "        avg_height = (tops[index] + bottoms[index])/2\n",
    "\n",
    "        is_left_initialized, last_left_center, left = find_point(histogram,\n",
    "                                                                 avg_height,\n",
    "                                                                 is_left_initialized, \n",
    "                                                                 0, \n",
    "                                                                 int(hist_len/2), \n",
    "                                                                 last_left_center, \n",
    "                                                                 left)\n",
    "        \n",
    "        is_right_initialized, last_right_center, right = find_point(histogram,\n",
    "                                                                 avg_height,\n",
    "                                                                 is_right_initialized, \n",
    "                                                                 int(hist_len/2), \n",
    "                                                                 hist_len-1, \n",
    "                                                                 last_right_center, \n",
    "                                                                 right)\n",
    "            \n",
    "    #print(left)\n",
    "    \n",
    "    return left, right\n",
    "    \n",
    "\n",
    "left, right = get_lane_points(test_warped)\n",
    "\n",
    "def add_points(fig_, points_, marking_):\n",
    "    for pt_tuple in points_:\n",
    "        fig_.plot(pt_tuple[0],pt_tuple[1],marking_, markersize=30)\n",
    "\n",
    "\n",
    "\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(20,10))\n",
    "ax1.set_title('Original: Marked Lane Points')\n",
    "ax1.imshow(test_warped, cmap='gray')\n",
    "add_points(ax1, left, 'b.')\n",
    "add_points(ax1, right, 'r.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curve Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def fit_curve(points_):\n",
    "    # get x and y values\n",
    "    x_vals = np.asarray([pt_tuple[0] for pt_tuple in points_])\n",
    "    y_vals = np.asarray([pt_tuple[1] for pt_tuple in points_])\n",
    "    # Fit a second order polynomial\n",
    "    fit_coeff = np.polyfit(y_vals, x_vals, 2)\n",
    "    x_fit = fit_coeff[0]*y_vals**2 + fit_coeff[1]*y_vals + fit_coeff[2]\n",
    "    return x_fit, y_vals, fit_coeff\n",
    "\n",
    "def add_curve(fig_, x_fit_, y_vals_):\n",
    "    fig_.plot(x_fit_, y_vals_, color='green', linewidth=3)\n",
    "\n",
    "\n",
    "# grab image\n",
    "test_img = mpimg.imread('test_images/test5.jpg')\n",
    "\n",
    "# transforms\n",
    "_, combined_binary = combine_threshold(test_img)\n",
    "test_img_roi = hk_region_ofInterest(combined_binary)\n",
    "test_warped = perspective_warp(test_img_roi)\n",
    "\n",
    "# find the curve\n",
    "left, right = get_lane_points(test_warped)\n",
    "left_x_fit, left_y_vals, _ = fit_curve(left)\n",
    "right_x_fit, right_y_vals, _ = fit_curve(right)\n",
    "\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(20,10))\n",
    "ax1.set_title('Original: Marked Lane Points')\n",
    "ax1.imshow(test_warped, cmap='gray')\n",
    "add_points(ax1, left, 'b.')\n",
    "add_points(ax1, right, 'r.')\n",
    "add_curve(ax1, left_x_fit, left_y_vals)\n",
    "add_curve(ax1, right_x_fit, right_y_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def path_overlay(rgb_img_, left_fitx_, left_yvals_, right_fitx_, right_yvals_):\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(rgb_img_[:,:,0]).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx_, left_yvals_]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx_, right_yvals_])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    return cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "def gen_points_from_fit(num_points_, height_, y_min_, fit_coeff_):\n",
    "    y_gen = np.linspace(y_min_, height_-1, num=num_points_)\n",
    "    x_gen = fit_coeff_[0]*y_gen**2 + fit_coeff_[1]*y_gen + fit_coeff_[2]\n",
    "    return x_gen, y_gen\n",
    "    \n",
    "\n",
    "\n",
    "# grab image\n",
    "test_img = mpimg.imread('test_images/test5.jpg')\n",
    "\n",
    "# transforms\n",
    "_, combined_binary = combine_threshold(test_img)\n",
    "test_img_roi = hk_region_ofInterest(combined_binary)\n",
    "test_warped = perspective_warp(test_img_roi)\n",
    "\n",
    "# find the curve\n",
    "left, right = get_lane_points(test_warped)\n",
    "left_x_fit, left_y_vals, left_fit_coeff = fit_curve(left)\n",
    "right_x_fit, right_y_vals, right_fit_coeff = fit_curve(right)\n",
    "\n",
    "test_img_warped = perspective_warp(test_img)\n",
    "\n",
    "# create more points for the overlay\n",
    "NUM_OVERLAY_PTS = 10\n",
    "test_height = test_img.shape[0]\n",
    "left_x_gen, left_y_gen = gen_points_from_fit(NUM_OVERLAY_PTS, test_height, left_y_vals[-1], left_fit_coeff)\n",
    "right_x_gen, right_y_gen = gen_points_from_fit(NUM_OVERLAY_PTS, test_height, right_y_vals[-1], right_fit_coeff)\n",
    "\n",
    "# generate overlays\n",
    "warped_overlay = path_overlay(test_img_warped, left_x_gen, left_y_gen, right_x_gen, right_y_gen)\n",
    "unwarped_overlay = perspective_warp_inv(warped_overlay)\n",
    "\n",
    "# put overlays on images\n",
    "testImg_warp_overlay = cv2.addWeighted(test_img_warped, 1, warped_overlay, 0.3, 0)\n",
    "testImg_unwarp_overlay = cv2.addWeighted(test_img, 1, unwarped_overlay, 0.3, 0)\n",
    "\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.set_title('Overlay in Warped Image')\n",
    "ax1.imshow(testImg_warp_overlay)\n",
    "\n",
    "ax2.set_title('Overlay in Original Image')\n",
    "ax2.imshow(testImg_unwarp_overlay)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
